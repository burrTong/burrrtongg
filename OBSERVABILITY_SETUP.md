# ğŸš€ Setup Distributed Tracing with Tempo

## à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¹€à¸à¸´à¹ˆà¸¡ Tracing

### 1. à¹€à¸à¸´à¹ˆà¸¡ Dependencies à¹ƒà¸™ `build.gradle`

```gradle
dependencies {
    // Existing dependencies...
    
    // Add tracing support
    implementation 'io.micrometer:micrometer-tracing-bridge-otel'
    implementation 'io.opentelemetry:opentelemetry-exporter-otlp'
}
```

### 2. à¹€à¸à¸´à¹ˆà¸¡ Configuration à¹ƒà¸™ `application.properties`

```properties
# Tracing configuration
management.tracing.sampling.probability=1.0
management.otlp.tracing.endpoint=http://tempo:4318/v1/traces
```

### 3. Restart Backend

```bash
docker-compose down
docker-compose up --build -d
```

### 4. à¸—à¸”à¸ªà¸­à¸š Tracing

1. à¸—à¸³ requests à¹„à¸›à¸—à¸µà¹ˆ backend: `http://localhost:8080/api/products`
2. à¹€à¸›à¸´à¸” Grafana: `http://localhost:3000`
3. à¹„à¸›à¸—à¸µà¹ˆ **Explore** > à¹€à¸¥à¸·à¸­à¸ **Tempo**
4. Query: `{service.name="backend"}`
5. à¸„à¸¸à¸“à¸ˆà¸°à¹€à¸«à¹‡à¸™ trace timeline à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° request!

---

## ğŸ“Š Grafana Dashboard Setup

### à¸ªà¸£à¹‰à¸²à¸‡ Dashboard à¸ªà¸³à¸«à¸£à¸±à¸š Backend

#### 1. à¹€à¸›à¸´à¸” Grafana
```
http://localhost:3000
Username: admin
Password: admin
```

#### 2. à¸ªà¸£à¹‰à¸²à¸‡ Dashboard à¹ƒà¸«à¸¡à¹ˆ
- à¸„à¸¥à¸´à¸ **+** > **Create Dashboard**
- Add panels à¸•à¸²à¸¡à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡

---

### ğŸ“ˆ Panel 1: Request Rate

**Type:** Time Series Graph
**Data Source:** Prometheus
**Query:**
```promql
rate(http_server_requests_seconds_count{job="app-service"}[1m])
```
**Title:** "Requests per Second"
**Legend:** `{{uri}} - {{method}}`

---

### ğŸ“ˆ Panel 2: Response Time (p95, p99)

**Type:** Time Series Graph
**Data Source:** Prometheus
**Query A (p95):**
```promql
histogram_quantile(0.95, rate(http_server_requests_seconds_bucket[5m]))
```
**Query B (p99):**
```promql
histogram_quantile(0.99, rate(http_server_requests_seconds_bucket[5m]))
```
**Title:** "Response Time Percentiles"

---

### ğŸ“ˆ Panel 3: Error Rate

**Type:** Stat / Gauge
**Data Source:** Prometheus
**Query:**
```promql
sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m])) / sum(rate(http_server_requests_seconds_count[5m])) * 100
```
**Title:** "Error Rate (%)"
**Thresholds:** 
- Green: < 1%
- Yellow: 1-5%
- Red: > 5%

---

### ğŸ“ˆ Panel 4: Top 5 Slowest Endpoints

**Type:** Table
**Data Source:** Prometheus
**Query:**
```promql
topk(5, avg by (uri) (rate(http_server_requests_seconds_sum[5m]) / rate(http_server_requests_seconds_count[5m])))
```
**Title:** "Slowest Endpoints (Avg Response Time)"

---

### ğŸ“ˆ Panel 5: JVM Memory Usage

**Type:** Time Series Graph
**Data Source:** Prometheus
**Query:**
```promql
jvm_memory_used_bytes{area="heap"}
```
**Title:** "JVM Heap Memory Usage"
**Unit:** bytes

---

### ğŸ“ˆ Panel 6: CPU Usage

**Type:** Gauge
**Data Source:** Prometheus
**Query:**
```promql
system_cpu_usage * 100
```
**Title:** "CPU Usage (%)"
**Unit:** percent (0-100)

---

### ğŸ“ˆ Panel 7: Live Logs

**Type:** Logs
**Data Source:** Loki
**Query:**
```logql
{container_name="backend_app"}
```
**Title:** "Backend Logs (Live)"

---

## ğŸ¯ Use Cases

### Use Case 1: à¸«à¸² Slow Requests
```promql
# Requests à¸—à¸µà¹ˆà¸Šà¹‰à¸²à¸à¸§à¹ˆà¸² 1 à¸§à¸´à¸™à¸²à¸—à¸µ
http_server_requests_seconds_sum / http_server_requests_seconds_count > 1
```

### Use Case 2: Monitor Order Service
```logql
# Logs à¸‚à¸­à¸‡ OrderService
{container_name="backend_app"} |= "OrderService"
```

### Use Case 3: Track Errors
```logql
# Error logs à¸à¸£à¹‰à¸­à¸¡ context
{container_name="backend_app"} |= "ERROR" | json
```

### Use Case 4: Correlate Metrics + Logs + Traces
1. à¹€à¸«à¹‡à¸™ spike à¹ƒà¸™ Response Time (Prometheus)
2. à¸”à¸¹ logs à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸™à¸±à¹‰à¸™ (Loki)
3. à¹€à¸›à¸´à¸” trace à¹€à¸à¸·à¹ˆà¸­à¸”à¸¹ bottleneck (Tempo)

---

## ğŸ” Alerting (Optional)

### à¸ªà¸£à¹‰à¸²à¸‡ Alert Rules à¹ƒà¸™ Prometheus

**File:** `docker/prometheus/prometheus.yml`

```yaml
rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets: []
```

**File:** `docker/prometheus/alert_rules.yml`

```yaml
groups:
  - name: backend_alerts
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: |
          sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m])) 
          / sum(rate(http_server_requests_seconds_count[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }}"

      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95, 
            rate(http_server_requests_seconds_bucket[5m])
          ) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time"
          description: "P95 response time is {{ $value }}s"
```

---

## ğŸ“š Resources

- [Prometheus Query Language](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [LogQL (Loki)](https://grafana.com/docs/loki/latest/query/)
- [Tempo Tracing](https://grafana.com/docs/tempo/latest/)
- [Micrometer Documentation](https://micrometer.io/docs)
- [Grafana Dashboards](https://grafana.com/grafana/dashboards/)

---

## ğŸ“ Quick Tips

### Prometheus
- à¹ƒà¸Šà¹‰ `rate()` à¸ªà¸³à¸«à¸£à¸±à¸š counters
- à¹ƒà¸Šà¹‰ `histogram_quantile()` à¸ªà¸³à¸«à¸£à¸±à¸š percentiles
- à¹ƒà¸Šà¹‰ `topk()` à¸«à¸² top N values

### Loki
- `|=` - contains
- `!=` - not contains
- `|~ "regex"` - regex match
- `| json` - parse JSON logs

### Grafana
- à¸à¸” **Ctrl+K** à¹€à¸à¸·à¹ˆà¸­à¸„à¹‰à¸™à¸«à¸²à¸­à¸°à¹„à¸£à¸à¹‡à¹„à¸”à¹‰
- à¹ƒà¸Šà¹‰ **Variables** ($variable) à¹€à¸à¸·à¹ˆà¸­à¸—à¸³ dynamic dashboards
- **Save** dashboard à¸šà¹ˆà¸­à¸¢à¹†!

---

## âœ… Checklist

- [ ] Prometheus scraping metrics (http://localhost:9090/targets)
- [ ] Loki receiving logs (Query à¹ƒà¸™ Grafana Explore)
- [ ] Tempo ready for traces (Add tracing dependencies)
- [ ] Grafana datasources configured
- [ ] Create custom dashboard
- [ ] Set up alerts (Optional)
